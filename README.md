
# ğŸš€ Agentic RAG with LangChain and Gemini  
### Multi-Source Question Answering System

---

## ğŸ§  Overview
This project implements an **Agentic Retrieval-Augmented Generation (RAG)** system using **LangChain** and **Google Gemini**.

Unlike traditional RAG pipelines, this system uses an **LLM-driven agent** that can dynamically decide **when** and **which** data source to queryâ€”such as a vector database, Wikipedia, or arXivâ€”based on the userâ€™s question.

The focus of this project is **agent-based orchestration**, real-world debugging, and handling framework + model constraints realistically.

---

## âœ¨ Key Features
- ğŸ¤– **Agent-based reasoning** using LangChain (v1.x)
- ğŸ” **Multi-source retrieval**
  - Vector store (document RAG)
  - Wikipedia (general knowledge)
  - arXiv (research papers)
- ğŸ› ï¸ **Explicit Gemini-safe tool contracts**
- âš ï¸ Handles real-world Gemini tool-calling constraints
- ğŸ§© Built with modern LangChain architecture (Runnable-based agents)

---

## ğŸ—ï¸ System Architecture

```text
User Query
    â†“
Gemini Agent (Reasoning)
    â†“
Selects Tool(s)
    â”œâ”€â”€ Vector Store Retriever
    â”œâ”€â”€ Wikipedia Search
    â””â”€â”€ arXiv Search
    â†“
Tool Observations
    â†“
Final Grounded Answer
````

ğŸ”¹ Retrieval is **conditional**, not mandatory
ğŸ”¹ The agent decides whether external knowledge is required

---

## â“ Why Agentic RAG?

### Traditional RAG

```text
Query â†’ Retriever â†’ LLM â†’ Answer
```

### Agentic RAG (this project)

```text
Query â†’ LLM decides â†’ Tool(s) â†’ Observation â†’ Final Answer
```

### Benefits

* Smarter and selective retrieval
* Reduced unnecessary context injection
* Better handling of mixed queries (factual + research)
* Clear separation between **reasoning** and **retrieval**

---

## ğŸ› ï¸ Tool Design (Important)

Google Gemini enforces **strict validation rules** for tool schemas.

To ensure stability:

* âœ… All tools are **manually wrapped**
* âœ… Tool names follow **Gemini-safe naming rules**
* âŒ Auto-generated LangChain community tools are **not passed directly**

This prevents runtime failures and makes agent behavior predictable.

---

## ğŸ¤– Gemini Model Choice

The project uses:

```text
models/gemini-2.5-flash
```

### Why?

* Fully supported by the Gemini **v1beta** API
* Stable for tool calling and agent execution
* Avoids model availability and 404 errors

---

## ğŸ§° Tech Stack

* **Python**
* **LangChain (v1.x)**
* **Google Gemini (ChatGoogleGenerativeAI)**
* **Vector Store** for document retrieval
* **Wikipedia & arXiv APIs**

---

## ğŸ§ª Example Queries

* *â€œSummarize LangChain and its core conceptsâ€*

<img width="1817" height="682" alt="image" src="https://github.com/user-attachments/assets/d83b6c12-a704-4d55-a640-57d543a301ef" />


---

## ğŸ¯ Project Motivation

This project was built as a **hands-on learning milestone** to deeply understand:

* Modern LangChain agent APIs
* Tool-calling constraints with Gemini
* Real-world GenAI debugging (not tutorial demos)
* Design trade-offs between pipelines and agents

The emphasis is on **system design and decision-making**, not just output quality.

---

## ğŸ”® Future Improvements

* Migrate agent logic to **LangGraph** for better state control
* Add evaluation metrics for retrieval quality
* Support switching between **Gemini and local LLMs (Ollama)**
* Convert notebook implementation into a production-ready service

---

